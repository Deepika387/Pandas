{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80325642",
   "metadata": {},
   "source": [
    "# 1.Write a Pandas program to create a dataframe from a dictionary and display it.\n",
    "Sample data: {'X':[78,85,96,80,86], 'Y':[84,94,89,83,86],'Z':[86,97,96,72,83]}\n",
    "Expected Output:\n",
    "    X   Y   Z                                                         \n",
    "0  78  84  86                                                        \n",
    "1  85  94  97                                                         \n",
    "2  96  89  96                                                      \n",
    "3  80  83  72                                                         \n",
    "4  86  86  83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b41e8b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    X   Y   Z\n",
      "0  78  84  86\n",
      "1  85  94  97\n",
      "2  96  89  96\n",
      "3  80  83  72\n",
      "4  86  86  83\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the dictionary\n",
    "data = {'X': [78, 85, 96, 80, 86],\n",
    "        'Y': [84, 94, 89, 83, 86],\n",
    "        'Z': [86, 97, 96, 72, 83]}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a6bc58",
   "metadata": {},
   "source": [
    "# 2. Write a Pandas program to create and display a DataFrame from a specified dictionary data which has the index labels.\n",
    "Sample Python dictionary data and list labels:\n",
    "exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "Expected Output:\n",
    "   attempts       name qualify  score                              \n",
    "a         1  Anastasia     yes   12.5                                 \n",
    "b         3       Dima      no    9.0                                 \n",
    "....                              \n",
    "i         2      Kevin      no    8.0                                \n",
    "j         1      Jonas     yes   19.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f8944e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name  score  attempts qualify\n",
      "a  Anastasia   12.5         1     yes\n",
      "b       Dima    9.0         3      no\n",
      "c  Katherine   16.5         2     yes\n",
      "d      James    NaN         3      no\n",
      "e      Emily    9.0         2      no\n",
      "f    Michael   20.0         3     yes\n",
      "g    Matthew   14.5         1     yes\n",
      "h      Laura    NaN         1      no\n",
      "i      Kevin    8.0         2      no\n",
      "j      Jonas   19.0         1     yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the dictionary data\n",
    "exam_data = {\n",
    "    'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "    'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "    'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "    'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']\n",
    "}\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "# Create the DataFrame with index labels\n",
    "df = pd.DataFrame(exam_data, index=labels)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4561c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ae65f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6148fdd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ebf582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73240715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec52561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "756254ed",
   "metadata": {},
   "source": [
    "# 47. Write a Pandas program to get the specified row value of a given DataFrame.\n",
    "Sample data:\n",
    "Original DataFrame\n",
    "   col1  col2  col3\n",
    "0     1     4     7\n",
    "1     2     5     8\n",
    "2     3     6    12\n",
    "3     4     9     1\n",
    "4     7     5    11\n",
    "Value of Row\n",
    "col1    1\n",
    "col2    4\n",
    "col3    7\n",
    "Name: 0, dtype: int64\n",
    "Value of Row4\n",
    "col1    4\n",
    "col2    9\n",
    "col3    1\n",
    "Name: 3, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3e751cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   col1  col2  col3\n",
      "0     1     4     7\n",
      "1     2     5     8\n",
      "2     3     6    12\n",
      "3     4     9     1\n",
      "4     7     5    11\n",
      "\n",
      "Value of Row 0:\n",
      "col1    1\n",
      "col2    4\n",
      "col3    7\n",
      "Name: 0, dtype: int64\n",
      "\n",
      "Value of Row 3:\n",
      "col1    4\n",
      "col2    9\n",
      "col3    1\n",
      "Name: 3, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "data = {'col1': [1, 2, 3, 4, 7],\n",
    "        'col2': [4, 5, 6, 9, 5],\n",
    "        'col3': [7, 8, 12, 1, 11]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Get the value of Row 0\n",
    "row_value_0 = df.loc[0]\n",
    "\n",
    "# Print the value of Row 0\n",
    "print(\"\\nValue of Row 0:\")\n",
    "print(row_value_0)\n",
    "\n",
    "# Get the value of Row 3\n",
    "row_value_3 = df.loc[3]\n",
    "\n",
    "# Print the value of Row 3\n",
    "print(\"\\nValue of Row 3:\")\n",
    "print(row_value_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264741f8",
   "metadata": {},
   "source": [
    "# 48. Write a Pandas program to get the datatypes of columns of a DataFrame.\n",
    "Sample data:\n",
    "Original DataFrame:\n",
    "   attempts       name qualify  score\n",
    "0         1  Anastasia     yes   12.5\n",
    "1         3       Dima      no    9.0\n",
    ".......\n",
    "8         2      Kevin      no    8.0\n",
    "9         1      Jonas     yes   19.0\n",
    "Data types of the columns of the said DataFrame:\n",
    "attempts      int64\n",
    "name         object\n",
    "qualify      object\n",
    "score       float64\n",
    "dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1676d9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   attempts       name qualify  score\n",
      "0         1  Anastasia     yes   12.5\n",
      "1         3       Dima      no    9.0\n",
      "2         2  Katherine     yes   16.5\n",
      "3         3      James      no   10.0\n",
      "4         2      Emily      no    9.0\n",
      "5         3    Michael     yes   20.0\n",
      "6         1    Matthew     yes   14.5\n",
      "7         1      Laura      no    NaN\n",
      "8         2      Kevin      no    8.0\n",
      "9         1      Jonas     yes   19.0\n",
      "\n",
      "Data types of the columns of the said DataFrame:\n",
      "attempts      int64\n",
      "name         object\n",
      "qualify      object\n",
      "score       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "data = {'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "        'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "        'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes'],\n",
    "        'score': [12.5, 9.0, 16.5, 10.0, 9.0, 20.0, 14.5, None, 8.0, 19.0]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Get the datatypes of the columns\n",
    "column_datatypes = df.dtypes\n",
    "\n",
    "# Print the datatypes\n",
    "print(\"\\nData types of the columns of the said DataFrame:\")\n",
    "print(column_datatypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c8e42c",
   "metadata": {},
   "source": [
    "# 49. Write a Pandas program to append data to an empty DataFrame.\n",
    "Sample data:\n",
    "Original DataFrame:\n",
    "After appending some data:\n",
    "   col1  col2\n",
    "0     0     0\n",
    "1     1     1\n",
    "2     2     2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00d3d112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "After appending some data:\n",
      "   col1  col2\n",
      "0     0     0\n",
      "1     1     1\n",
      "2     2     2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshit Koche\\AppData\\Local\\Temp\\ipykernel_16720\\2957597319.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(pd.DataFrame(data))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Print the original empty DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Append some data to the DataFrame\n",
    "data = {'col1': [0, 1, 2], 'col2': [0, 1, 2]}\n",
    "df = df.append(pd.DataFrame(data))\n",
    "\n",
    "# Print the DataFrame after appending data\n",
    "print(\"\\nAfter appending some data:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb9acc7",
   "metadata": {},
   "source": [
    "# 50. Write a Pandas program to sort a given DataFrame by two or more columns.\n",
    "Sample data:\n",
    "Original DataFrame:\n",
    "   attempts       name qualify  score\n",
    "0         1  Anastasia     yes   12.5 \n",
    "1         3       Dima      no    9.0\n",
    "........\n",
    "8         2      Kevin      no    8.0\n",
    "9         1      Jonas     yes   19.0\n",
    "\n",
    "Sort the above DataFrame on attempts, name:\n",
    "   attempts       name qualify  score\n",
    "0         1  Anastasia     yes   12.5\n",
    "9         1      Jonas     yes   19.0\n",
    "7         1      Laura      no    NaN\n",
    "6         1    Matthew     yes   14.5\n",
    "4         2      Emily      no    9.0\n",
    "2         2  Katherine     yes   16.5\n",
    "8         2      Kevin      no    8.0\n",
    "1         3       Dima      no    9.0\n",
    "3         3      James      no    NaN\n",
    "5         3    Michael     yes   20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78a8e255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   attempts       name qualify  score\n",
      "0         1  Anastasia     yes   12.5\n",
      "1         3       Dima      no    9.0\n",
      "2         2  Katherine     yes   16.5\n",
      "3         3      James      no    NaN\n",
      "4         2      Emily      no    9.0\n",
      "5         3    Michael     yes   20.0\n",
      "6         1    Matthew     yes   14.5\n",
      "7         1      Laura      no    NaN\n",
      "8         2      Kevin      no    8.0\n",
      "9         1      Jonas     yes   19.0\n",
      "\n",
      "Sorted DataFrame:\n",
      "   attempts       name qualify  score\n",
      "0         1  Anastasia     yes   12.5\n",
      "9         1      Jonas     yes   19.0\n",
      "7         1      Laura      no    NaN\n",
      "6         1    Matthew     yes   14.5\n",
      "4         2      Emily      no    9.0\n",
      "2         2  Katherine     yes   16.5\n",
      "8         2      Kevin      no    8.0\n",
      "1         3       Dima      no    9.0\n",
      "3         3      James      no    NaN\n",
      "5         3    Michael     yes   20.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "    'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "    'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes'],\n",
    "    'score': [12.5, 9.0, 16.5, None, 9.0, 20.0, 14.5, None, 8.0, 19.0]\n",
    "})\n",
    "\n",
    "# Print the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Sort the DataFrame on attempts, name\n",
    "sorted_df = df.sort_values(['attempts', 'name'])\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "print(\"\\nSorted DataFrame:\")\n",
    "print(sorted_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de4c03",
   "metadata": {},
   "source": [
    "# 51. Write a Pandas program to convert the datatype of a given column (floats to ints).\n",
    "Sample data:\n",
    "Original DataFrame:\n",
    "attempts name qualify score\n",
    "0 1 Anastasia yes 12.50\n",
    "1 3 Dima no 9.10\n",
    "......\n",
    "8 2 Kevin no 8.80\n",
    "9 1 Jonas yes 19.13\n",
    "Data types of the columns of the said DataFrame:\n",
    "attempts int64\n",
    "name object\n",
    "qualify object\n",
    "score float64\n",
    "dtype: object\n",
    "Now change the Data type of 'score' column from float to int:\n",
    "attempts name qualify score\n",
    "0 1 Anastasia yes 12\n",
    "1 3 Dima no 9\n",
    "2 2 Katherine yes 16\n",
    "3 3 James no 12\n",
    "4 2 Emily no 9\n",
    "5 3 Michael yes 20\n",
    "6 1 Matthew yes 14\n",
    "7 1 Laura no 11\n",
    "8 2 Kevin no 8\n",
    "9 1 Jonas yes 19\n",
    "Data types of the columns of the DataFrame now:\n",
    "attempts int64\n",
    "name object\n",
    "qualify object\n",
    "score int64\n",
    "dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b530ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   attempts       name qualify  score\n",
      "0         1  Anastasia     yes  12.50\n",
      "1         3       Dima      no   9.10\n",
      "2         2  Katherine     yes  16.29\n",
      "3         3      James      no  12.40\n",
      "4         2      Emily      no   9.35\n",
      "5         3    Michael     yes  20.00\n",
      "6         1    Matthew     yes  14.50\n",
      "7         1      Laura      no  11.20\n",
      "8         2      Kevin      no   8.80\n",
      "9         1      Jonas     yes  19.13\n",
      "Data types of the columns of the said DataFrame:\n",
      "attempts      int64\n",
      "name         object\n",
      "qualify      object\n",
      "score       float64\n",
      "dtype: object\n",
      "DataFrame after changing the data type of 'score' column:\n",
      "   attempts       name qualify  score\n",
      "0         1  Anastasia     yes     12\n",
      "1         3       Dima      no      9\n",
      "2         2  Katherine     yes     16\n",
      "3         3      James      no     12\n",
      "4         2      Emily      no      9\n",
      "5         3    Michael     yes     20\n",
      "6         1    Matthew     yes     14\n",
      "7         1      Laura      no     11\n",
      "8         2      Kevin      no      8\n",
      "9         1      Jonas     yes     19\n",
      "Data types of the columns of the DataFrame now:\n",
      "attempts     int64\n",
      "name        object\n",
      "qualify     object\n",
      "score        int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "    'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "    'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes'],\n",
    "    'score': [12.50, 9.10, 16.29, 12.40, 9.35, 20.00, 14.50, 11.20, 8.80, 19.13]\n",
    "})\n",
    "\n",
    "# Print the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Check the data types of the columns\n",
    "print(\"Data types of the columns of the said DataFrame:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Convert the datatype of 'score' column from float to int\n",
    "df['score'] = df['score'].astype(int)\n",
    "\n",
    "# Print the DataFrame after changing the data type\n",
    "print(\"DataFrame after changing the data type of 'score' column:\")\n",
    "print(df)\n",
    "\n",
    "# Check the data types of the columns again\n",
    "print(\"Data types of the columns of the DataFrame now:\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec637f",
   "metadata": {},
   "source": [
    "# 52. Write a Pandas program to remove infinite values from a given DataFrame.\n",
    "Sample data:\n",
    "Original DataFrame:\n",
    "0\n",
    "0 1000.000000\n",
    "1 2000.000000\n",
    "2 3000.000000\n",
    "3 -4000.000000\n",
    "4 inf\n",
    "5 -inf\n",
    "Removing infinite values:\n",
    "0\n",
    "0 1000.0\n",
    "1 2000.0\n",
    "2 3000.0\n",
    "3 -4000.0\n",
    "4 NaN\n",
    "5 NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06122fa3",
   "metadata": {},
   "source": [
    "# 53. Write a Pandas program to insert a given column at a specific column index in a DataFrame.\n",
    "Sample data:\n",
    "Original DataFrame\n",
    "col2 col3\n",
    "0 4 7\n",
    "1 5 8\n",
    "2 6 12\n",
    "3 9 1\n",
    "4 5 11\n",
    "New DataFrame\n",
    "col1 col2 col3\n",
    "0 1 4 7\n",
    "1 2 5 8\n",
    "2 3 6 12\n",
    "3 4 9 1\n",
    "4 7 5 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8faaaf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8af487e2",
   "metadata": {},
   "source": [
    "# 54. Write a Pandas program to convert a given list of lists into a Dataframe.\n",
    "Sample data:\n",
    "Original list of lists:\n",
    "[[2, 4], [1, 3]]\n",
    "New DataFrame\n",
    "col1 col2\n",
    "0 2 4\n",
    "1 1 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef1c2a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New DataFrame:\n",
      "   col1  col2\n",
      "0     2     4\n",
      "1     1     3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Original list of lists\n",
    "original_list = [[2, 4], [1, 3]]\n",
    "\n",
    "# Convert list of lists to DataFrame\n",
    "df = pd.DataFrame(original_list, columns=['col1', 'col2'])\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(\"New DataFrame:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bf3b0e",
   "metadata": {},
   "source": [
    "# 55. Write a Pandas program to group by the first column and get second column as lists in rows.\n",
    "Sample data:\n",
    "Original DataFrame\n",
    "col1 col2\n",
    "0 C1 1\n",
    "1 C1 2\n",
    "2 C2 3\n",
    "3 C2 3\n",
    "4 C2 4\n",
    "5 C3 6\n",
    "6 C2 5\n",
    "Group on the col1:\n",
    "col1\n",
    "C1 [1, 2]\n",
    "C2 [3, 3, 4, 5]\n",
    "C3 [6]\n",
    "Name: col2, dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ed3925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col1\n",
      "C1          [1, 2]\n",
      "C2    [3, 3, 4, 5]\n",
      "C3             [6]\n",
      "Name: col2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Original DataFrame\n",
    "df = pd.DataFrame({'col1': ['C1', 'C1', 'C2', 'C2', 'C2', 'C3', 'C2'],\n",
    "                   'col2': [1, 2, 3, 3, 4, 6, 5]})\n",
    "\n",
    "# Group by col1 and get col2 as lists in rows\n",
    "result = df.groupby('col1')['col2'].apply(list)\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9e2822",
   "metadata": {},
   "source": [
    "# 56. Write a Pandas program to get column index from column name of a given DataFrame.\n",
    "Sample Output:\n",
    "Original DataFrame\n",
    "col1 col2 col3\n",
    "0 1 4 7\n",
    "1 2 5 8\n",
    "2 3 6 12\n",
    "3 4 9 1\n",
    "4 7 5 11\n",
    "Index of 'col2'\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95754544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of 'col2': 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "data = {'col1': [1, 2, 3, 4, 7],\n",
    "        'col2': [4, 5, 6, 9, 5],\n",
    "        'col3': [7, 8, 12, 1, 11]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Get the column index of 'col2'\n",
    "column_name = 'col2'\n",
    "column_index = df.columns.get_loc(column_name)\n",
    "\n",
    "# Print the column index\n",
    "print(\"Index of '{}': {}\".format(column_name, column_index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa84bc5c",
   "metadata": {},
   "source": [
    "# 57. Write a Pandas program to count number of columns of a DataFrame.\n",
    "Sample Output:\n",
    "Original DataFrame\n",
    "col1 col2 col3\n",
    "0 1 4 7\n",
    "1 2 5 8\n",
    "2 3 6 12\n",
    "3 4 9 1\n",
    "4 7 5 11\n",
    "Number of columns:\n",
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9da1822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "data = {'col1': [1, 2, 3, 4, 7],\n",
    "        'col2': [4, 5, 6, 9, 5],\n",
    "        'col3': [7, 8, 12, 1, 11]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Count the number of columns\n",
    "num_columns = df.shape[1]\n",
    "\n",
    "# Print the number of columns\n",
    "print(\"Number of columns:\", num_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b9d86a",
   "metadata": {},
   "source": [
    "# 58. Write a Pandas program to select all columns, except one given column in a DataFrame.\n",
    "Sample Output:\n",
    "Original DataFrame\n",
    "col1 col2 col3\n",
    "0 1 4 7\n",
    "1 2 5 8\n",
    "2 3 6 12\n",
    "3 4 9 1\n",
    "4 7 5 11\n",
    "All columns except 'col3':\n",
    "col1 col2\n",
    "0 1 4\n",
    "1 2 5\n",
    "2 3 6\n",
    "3 4 9\n",
    "4 7 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b21a672c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   col1  col2  col3\n",
      "0     1     4     7\n",
      "1     2     5     8\n",
      "2     3     6    12\n",
      "3     4     9     1\n",
      "4     7     5    11\n",
      "All columns except 'col3':\n",
      "   col1  col2\n",
      "0     1     4\n",
      "1     2     5\n",
      "2     3     6\n",
      "3     4     9\n",
      "4     7     5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "df = pd.DataFrame({'col1': [1, 2, 3, 4, 7],\n",
    "                   'col2': [4, 5, 6, 9, 5],\n",
    "                   'col3': [7, 8, 12, 1, 11]})\n",
    "\n",
    "# Print the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Select all columns except 'col3'\n",
    "columns_except_col3 = df.drop('col3', axis=1)\n",
    "print(\"All columns except 'col3':\")\n",
    "print(columns_except_col3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4f961d",
   "metadata": {},
   "source": [
    "# 59. Write a Pandas program to get first n records of a DataFrame.\n",
    "Sample Output:\n",
    "Original DataFrame\n",
    "col1 col2 col3\n",
    "0 1 4 7\n",
    "1 2 5 5\n",
    "2 3 6 8\n",
    "3 4 9 12\n",
    "4 7 5 1\n",
    "5 11 0 11\n",
    "First 3 rows of the said DataFrame':\n",
    "col1 col2 col3\n",
    "0 1 4 7\n",
    "1 2 5 5\n",
    "2 3 6 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "975d88b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   col1  col2  col3\n",
      "0     1     4     7\n",
      "1     2     5     5\n",
      "2     3     6     8\n",
      "3     4     9    12\n",
      "4     7     5     1\n",
      "5    11     0    11\n",
      "First 3 rows of the DataFrame:\n",
      "   col1  col2  col3\n",
      "0     1     4     7\n",
      "1     2     5     5\n",
      "2     3     6     8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "df = pd.DataFrame({'col1': [1, 2, 3, 4, 7, 11],\n",
    "                   'col2': [4, 5, 6, 9, 5, 0],\n",
    "                   'col3': [7, 5, 8, 12, 1, 11]})\n",
    "\n",
    "# Print the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Get the first n rows of the DataFrame\n",
    "n = 3  # Number of rows to get\n",
    "first_n_rows = df.head(n)\n",
    "print(\"First {} rows of the DataFrame:\".format(n))\n",
    "print(first_n_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d24f756",
   "metadata": {},
   "source": [
    "# 60. Write a Pandas program to get last n records of a DataFrame.\n",
    "Sample Output:\n",
    "Original DataFrame\n",
    "col1 col2 col3\n",
    "0 1 4 7\n",
    "1 2 5 5\n",
    "2 3 6 8\n",
    "3 4 9 12\n",
    "4 7 5 1\n",
    "5 11 0 11\n",
    "Last 3 rows of the said DataFrame':\n",
    "col1 col2 col3\n",
    "3 4 9 12\n",
    "4 7 5 1\n",
    "5 11 0 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c71bc1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 3 rows of the DataFrame:\n",
      "   col1  col2  col3\n",
      "3     4     9    12\n",
      "4     7     5     1\n",
      "5    11     0    11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Original DataFrame\n",
    "df = pd.DataFrame({'col1': [1, 2, 3, 4, 7, 11],\n",
    "                   'col2': [4, 5, 6, 9, 5, 0],\n",
    "                   'col3': [7, 5, 8, 12, 1, 11]})\n",
    "\n",
    "# Get the last 3 rows of the DataFrame\n",
    "last_n_rows = df.tail(3)\n",
    "\n",
    "# Print the last n rows\n",
    "print(\"Last 3 rows of the DataFrame:\")\n",
    "print(last_n_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08a9dd0",
   "metadata": {},
   "source": [
    "# 61. Write a Pandas program to get topmost n records within each group of a DataFrame.\n",
    "Sample Output:\n",
    "Original DataFrame\n",
    "col1 col2 col3\n",
    "0 1 4 7\n",
    "1 2 5 5\n",
    "2 3 6 8\n",
    "3 4 9 12\n",
    "4 7 5 1\n",
    "5 11 0 11\n",
    "topmost n records within each group of a DataFrame:\n",
    "col1 col2 col3\n",
    "5 11 0 11\n",
    "4 7 5 1\n",
    "3 4 9 12\n",
    "col1 col2 col3\n",
    "3 4 9 12\n",
    "2 3 6 8\n",
    "1 2 5 5\n",
    "4 7 5 1\n",
    "col1 col2 col3\n",
    "3 4 9 12\n",
    "5 11 0 11\n",
    "2 3 6 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aee5a99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   col1  col2  col3\n",
      "0     1     4     7\n",
      "1     2     5     5\n",
      "2     3     6     8\n",
      "3     4     9    12\n",
      "4     7     5     1\n",
      "5    11     0    11\n",
      "Topmost 3 records within each group of a DataFrame:\n",
      "   col1  col2  col3\n",
      "0     1     4     7\n",
      "1     2     5     5\n",
      "2     3     6     8\n",
      "3     4     9    12\n",
      "4     7     5     1\n",
      "5    11     0    11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "df = pd.DataFrame({'col1': [1, 2, 3, 4, 7, 11],\n",
    "                   'col2': [4, 5, 6, 9, 5, 0],\n",
    "                   'col3': [7, 5, 8, 12, 1, 11]})\n",
    "\n",
    "# Print the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Get topmost n records within each group\n",
    "n = 3  # Number of records to get from each group\n",
    "grouped = df.groupby('col1').head(n)\n",
    "print(\"Topmost {} records within each group of a DataFrame:\".format(n))\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50628375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bdff08b",
   "metadata": {},
   "source": [
    "# 62. Write a Pandas program to remove first n rows of a given DataFrame.\n",
    "Sample Output:\n",
    "Original DataFrame\n",
    "col1 col2 col3\n",
    "0 1 4 7\n",
    "1 2 5 5\n",
    "2 3 6 8\n",
    "3 4 9 12\n",
    "4 7 5 1\n",
    "5 11 0 11\n",
    "After removing first 3 rows of the said DataFrame:\n",
    "col1 col2 col3\n",
    "3 4 9 12\n",
    "4 7 5 1\n",
    "5 11 0 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82c9ff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2  col3\n",
      "3     4     9    12\n",
      "4     7     5     1\n",
      "5    11     0    11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "data = {'col1': [1, 2, 3, 4, 7, 11],\n",
    "        'col2': [4, 5, 6, 9, 5, 0],\n",
    "        'col3': [7, 5, 8, 12, 1, 11]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove the first 3 rows\n",
    "n = 3\n",
    "df = df.iloc[n:]\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f9c277",
   "metadata": {},
   "source": [
    "# 63. Write a Pandas program to remove last n rows of a given DataFrame.\n",
    "Sample Output:\n",
    "Original DataFrame\n",
    "col1 col2 col3\n",
    "0 1 4 7\n",
    "1 2 5 5\n",
    "2 3 6 8\n",
    "3 4 9 12\n",
    "4 7 5 1\n",
    "5 11 0 11\n",
    "After removing last 3 rows of the said DataFrame:\n",
    "col1 col2 col3\n",
    "0 1 4 7\n",
    "1 2 5 5\n",
    "2 3 6 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "852ddaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2  col3\n",
      "0     1     4     7\n",
      "1     2     5     5\n",
      "2     3     6     8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "data = {'col1': [1, 2, 3, 4, 7, 11],\n",
    "        'col2': [4, 5, 6, 9, 5, 0],\n",
    "        'col3': [7, 5, 8, 12, 1, 11]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove the last 3 rows\n",
    "n = 3\n",
    "df = df.iloc[:-n]\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a58de4f",
   "metadata": {},
   "source": [
    "# 64. Write a Pandas program to add a prefix or suffix to all columns of a given DataFrame.\n",
    "Sample Output:\n",
    "Original DataFrame\n",
    "W X Y Z\n",
    "0 68 78 84 86\n",
    "1 75 85 94 97\n",
    "2 86 96 89 96\n",
    "3 80 80 83 72\n",
    "4 66 86 86 83\n",
    "Add prefix:\n",
    "A_W A_X A_Y A_Z\n",
    "0 68 78 84 86\n",
    "1 75 85 94 97\n",
    "2 86 96 89 96\n",
    "3 80 80 83 72\n",
    "4 66 86 86 83\n",
    "Add suffix:\n",
    "W_1 X_1 Y_1 Z_1\n",
    "0 68 78 84 86\n",
    "1 75 85 94 97\n",
    "2 86 96 89 96\n",
    "3 80 80 83 72\n",
    "4 66 86 86 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c17643af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "    W   X   Y   Z\n",
      "0  68  78  84  86\n",
      "1  75  85  94  97\n",
      "2  86  96  89  96\n",
      "3  80  80  83  72\n",
      "4  66  86  86  83\n",
      "Add prefix:\n",
      "   A_W  A_X  A_Y  A_Z\n",
      "0   68   78   84   86\n",
      "1   75   85   94   97\n",
      "2   86   96   89   96\n",
      "3   80   80   83   72\n",
      "4   66   86   86   83\n",
      "Add suffix:\n",
      "   W_1  X_1  Y_1  Z_1\n",
      "0   68   78   84   86\n",
      "1   75   85   94   97\n",
      "2   86   96   89   96\n",
      "3   80   80   83   72\n",
      "4   66   86   86   83\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "df = pd.DataFrame({'W': [68, 75, 86, 80, 66],\n",
    "                   'X': [78, 85, 96, 80, 86],\n",
    "                   'Y': [84, 94, 89, 83, 86],\n",
    "                   'Z': [86, 97, 96, 72, 83]})\n",
    "\n",
    "# Print the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Add prefix\n",
    "prefixed_columns = df.add_prefix('A_')\n",
    "print(\"Add prefix:\")\n",
    "print(prefixed_columns)\n",
    "\n",
    "# Add suffix\n",
    "suffixed_columns = df.add_suffix('_1')\n",
    "print(\"Add suffix:\")\n",
    "print(suffixed_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3e6eac",
   "metadata": {},
   "source": [
    "# 65. Write a Pandas program to reverse order (rows, columns) of a given DataFrame.\n",
    "Sample Output:\n",
    "Original DataFrame\n",
    "W X Y Z\n",
    "0 68 78 84 86\n",
    "1 75 85 94 97\n",
    "2 86 96 89 96\n",
    "3 80 80 83 72\n",
    "4 66 86 86 83\n",
    "Reverse column order:\n",
    "Z Y X W\n",
    "0 86 84 78 68\n",
    "1 97 94 85 75\n",
    "2 96 89 96 86\n",
    "3 72 83 80 80\n",
    "4 83 86 86 66\n",
    "Reverse row order:\n",
    "W X Y Z\n",
    "4 66 86 86 83\n",
    "3 80 80 83 72\n",
    "2 86 96 89 96\n",
    "1 75 85 94 97\n",
    "0 68 78 84 86\n",
    "Reverse row order and reset index:\n",
    "W X Y Z\n",
    "0 66 86 86 83\n",
    "1 80 80 83 72\n",
    "2 86 96 89 96\n",
    "3 75 85 94 97\n",
    "4 68 78 84 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a950eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "    W   X   Y   Z\n",
      "0  68  78  84  86\n",
      "1  75  85  94  97\n",
      "2  86  96  89  96\n",
      "3  80  80  83  72\n",
      "4  66  86  86  83\n",
      "Reverse column order:\n",
      "    Z   Y   X   W\n",
      "0  86  84  78  68\n",
      "1  97  94  85  75\n",
      "2  96  89  96  86\n",
      "3  72  83  80  80\n",
      "4  83  86  86  66\n",
      "Reverse row order:\n",
      "    W   X   Y   Z\n",
      "4  66  86  86  83\n",
      "3  80  80  83  72\n",
      "2  86  96  89  96\n",
      "1  75  85  94  97\n",
      "0  68  78  84  86\n",
      "Reverse row order and reset index:\n",
      "    W   X   Y   Z\n",
      "0  66  86  86  83\n",
      "1  80  80  83  72\n",
      "2  86  96  89  96\n",
      "3  75  85  94  97\n",
      "4  68  78  84  86\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "df = pd.DataFrame({'W': [68, 75, 86, 80, 66],\n",
    "                   'X': [78, 85, 96, 80, 86],\n",
    "                   'Y': [84, 94, 89, 83, 86],\n",
    "                   'Z': [86, 97, 96, 72, 83]})\n",
    "\n",
    "# Print the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Reverse column order\n",
    "reversed_columns = df.iloc[:, ::-1]\n",
    "print(\"Reverse column order:\")\n",
    "print(reversed_columns)\n",
    "\n",
    "# Reverse row order\n",
    "reversed_rows = df.iloc[::-1]\n",
    "print(\"Reverse row order:\")\n",
    "print(reversed_rows)\n",
    "\n",
    "# Reverse row order and reset index\n",
    "reversed_rows_reset_index = df.iloc[::-1].reset_index(drop=True)\n",
    "print(\"Reverse row order and reset index:\")\n",
    "print(reversed_rows_reset_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05477988",
   "metadata": {},
   "source": [
    "# 66. Write a Pandas program to select columns by data type of a given DataFrame.\n",
    "Sample Output:\n",
    "Original DataFrame\n",
    "name date_of_birth age\n",
    "0 Alberto Franco 17/05/2002 18.5\n",
    "1 Gino Mcneill 16/02/1999 21.2\n",
    "2 Ryan Parkes 25/09/1998 22.5\n",
    "3 Eesha Hinton 11/05/2002 22.0\n",
    "4 Syed Wharton 15/09/1997 23.0\n",
    "Select numerical columns\n",
    "age\n",
    "0 18.5\n",
    "1 21.2\n",
    "2 22.5\n",
    "3 22.0\n",
    "4 23.0\n",
    "Select string columns\n",
    "name date_of_birth\n",
    "0 Alberto Franco 17/05/2002\n",
    "1 Gino Mcneill 16/02/1999\n",
    "2 Ryan Parkes 25/09/1998\n",
    "3 Eesha Hinton 11/05/2002\n",
    "4 Syed Wharton 15/09/1997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b57b4caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "             name date_of_birth   age\n",
      "0  Alberto Franco    17/05/2002  18.5\n",
      "1    Gino Mcneill    16/02/1999  21.2\n",
      "2     Ryan Parkes    25/09/1998  22.5\n",
      "3    Eesha Hinton    11/05/2002  22.0\n",
      "4    Syed Wharton    15/09/1997  23.0\n",
      "Select numerical columns:\n",
      "    age\n",
      "0  18.5\n",
      "1  21.2\n",
      "2  22.5\n",
      "3  22.0\n",
      "4  23.0\n",
      "Select string columns:\n",
      "             name date_of_birth\n",
      "0  Alberto Franco    17/05/2002\n",
      "1    Gino Mcneill    16/02/1999\n",
      "2     Ryan Parkes    25/09/1998\n",
      "3    Eesha Hinton    11/05/2002\n",
      "4    Syed Wharton    15/09/1997\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "df = pd.DataFrame({'name': ['Alberto Franco', 'Gino Mcneill', 'Ryan Parkes', 'Eesha Hinton', 'Syed Wharton'],\n",
    "                   'date_of_birth': ['17/05/2002', '16/02/1999', '25/09/1998', '11/05/2002', '15/09/1997'],\n",
    "                   'age': [18.5, 21.2, 22.5, 22.0, 23.0]})\n",
    "\n",
    "# Print the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_columns = df.select_dtypes(include=[float, int])\n",
    "print(\"Select numerical columns:\")\n",
    "print(numerical_columns)\n",
    "\n",
    "# Select string columns\n",
    "string_columns = df.select_dtypes(include=[object])\n",
    "print(\"Select string columns:\")\n",
    "print(string_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15031af",
   "metadata": {},
   "source": [
    "# 67. Write a Pandas program to split a given DataFrame into two random subsets.\n",
    "Sample Output:\n",
    "Original Dataframe and shape:\n",
    "name date_of_birth age\n",
    "0 Alberto Franco 17/05/2002 18\n",
    "1 Gino Mcneill 16/02/1999 21\n",
    "2 Ryan Parkes 25/09/1998 22\n",
    "3 Eesha Hinton 11/05/2002 22\n",
    "4 Syed Wharton 15/09/1997 23\n",
    "(5, 3)\n",
    "Subset-1 and shape:\n",
    "name date_of_birth age\n",
    "1 Gino Mcneill 16/02/1999 21\n",
    "4 Syed Wharton 15/09/1997 23\n",
    "2 Ryan Parkes 25/09/1998 22\n",
    "(3, 3)\n",
    "Subset-2 and shape:\n",
    "name date_of_birth age\n",
    "0 Alberto Franco 17/05/2002 18\n",
    "3 Eesha Hinton 11/05/2002 22\n",
    "(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85488668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame and shape:\n",
      "             name date_of_birth  age\n",
      "0  Alberto Franco    17/05/2002   18\n",
      "1    Gino Mcneill    16/02/1999   21\n",
      "2     Ryan Parkes    25/09/1998   22\n",
      "3    Eesha Hinton    11/05/2002   22\n",
      "4    Syed Wharton    15/09/1997   23\n",
      "(5, 3)\n",
      "Subset-1 and shape:\n",
      "           name date_of_birth  age\n",
      "2   Ryan Parkes    25/09/1998   22\n",
      "1  Gino Mcneill    16/02/1999   21\n",
      "4  Syed Wharton    15/09/1997   23\n",
      "(3, 3)\n",
      "Subset-2 and shape:\n",
      "             name date_of_birth  age\n",
      "0  Alberto Franco    17/05/2002   18\n",
      "3    Eesha Hinton    11/05/2002   22\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "df = pd.DataFrame({'name': ['Alberto Franco', 'Gino Mcneill', 'Ryan Parkes', 'Eesha Hinton', 'Syed Wharton'],\n",
    "                   'date_of_birth': ['17/05/2002', '16/02/1999', '25/09/1998', '11/05/2002', '15/09/1997'],\n",
    "                   'age': [18, 21, 22, 22, 23]})\n",
    "\n",
    "# Print the original DataFrame and its shape\n",
    "print(\"Original DataFrame and shape:\")\n",
    "print(df)\n",
    "print(df.shape)\n",
    "\n",
    "# Split the DataFrame into two random subsets\n",
    "subset1 = df.sample(frac=0.6, random_state=1)  # First subset with 60% of the original data\n",
    "subset2 = df[~df.index.isin(subset1.index)]  # Second subset with the remaining data\n",
    "\n",
    "# Print the first subset and its shape\n",
    "print(\"Subset-1 and shape:\")\n",
    "print(subset1)\n",
    "print(subset1.shape)\n",
    "\n",
    "# Print the second subset and its shape\n",
    "print(\"Subset-2 and shape:\")\n",
    "print(subset2)\n",
    "print(subset2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f86ff0",
   "metadata": {},
   "source": [
    "# 68. Write a Pandas program to rename all columns with the same pattern of a given DataFrame.\n",
    "Sample Output:\n",
    "Original DataFrame\n",
    "Name Date_Of_Birth Age\n",
    "0 Alberto Franco 17/05/2002 18.5\n",
    "1 Gino Mcneill 16/02/1999 21.2\n",
    "2 Ryan Parkes 25/09/1998 22.5\n",
    "3 Eesha Hinton 11/05/2002 22.0\n",
    "4 Syed Wharton 15/09/1997 23.0\n",
    "Remove trailing (at the end) whitesapce and convert to lowercase of the columns name\n",
    "name date_of_birth age\n",
    "0 Alberto Franco 17/05/2002 18.5\n",
    "1 Gino Mcneill 16/02/1999 21.2\n",
    "2 Ryan Parkes 25/09/1998 22.5\n",
    "3 Eesha Hinton 11/05/2002 22.0\n",
    "4 Syed Wharton 15/09/1997 23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d9ebab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             name date_of_birth   age\n",
      "0  Alberto Franco    17/05/2002  18.5\n",
      "1    Gino Mcneill    16/02/1999  21.2\n",
      "2     Ryan Parkes    25/09/1998  22.5\n",
      "3    Eesha Hinton    11/05/2002  22.0\n",
      "4    Syed Wharton    15/09/1997  23.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "data = {'Name': ['Alberto Franco', 'Gino Mcneill', 'Ryan Parkes', 'Eesha Hinton', 'Syed Wharton'],\n",
    "        'Date_Of_Birth': ['17/05/2002', '16/02/1999', '25/09/1998', '11/05/2002', '15/09/1997'],\n",
    "        'Age': [18.5, 21.2, 22.5, 22.0, 23.0]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Rename columns based on the pattern\n",
    "df = df.rename(columns=lambda x: x.strip().lower())\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe35562",
   "metadata": {},
   "source": [
    "# 69. Write a Pandas program to merge datasets and check uniqueness.\n",
    "Sample Output:\n",
    "Original DataFrame:\n",
    "Name Date_Of_Birth Age\n",
    "0 Alberto Franco 17/05/2002 18.5\n",
    "1 Gino Mcneill 16/02/1999 21.2\n",
    "2 Ryan Parkes 25/09/1998 22.5\n",
    "3 Eesha Hinton 11/05/2002 22.0\n",
    "4 Syed Wharton 15/09/1997 23.0\n",
    "New DataFrames:\n",
    "Name Date_Of_Birth Age\n",
    "2 Ryan Parkes 25/09/1998 22.5\n",
    "3 Eesha Hinton 11/05/2002 22.0\n",
    "4 Syed Wharton 15/09/1997 23.0\n",
    "Name Date_Of_Birth Age\n",
    "0 Alberto Franco 17/05/2002 18.5\n",
    "1 Gino Mcneill 16/02/1999 21.2\n",
    "3 Eesha Hinton 11/05/2002 22.0\n",
    "4 Syed Wharton 15/09/1997 23.0\n",
    "\"one_to_one\": check if merge keys are unique in both left and right datasets:\"\n",
    "Name Date_Of_Birth Age\n",
    "0 Eesha Hinton 11/05/2002 22.0\n",
    "1 Syed Wharton 15/09/1997 23.0\n",
    "\"one_to_many\" or \"1:m\": check if merge keys are unique in left dataset:\n",
    "Name Date_Of_Birth Age\n",
    "0 Eesha Hinton 11/05/2002 22.0\n",
    "1 Syed Wharton 15/09/1997 23.0\n",
    "\"any_to_one\" or \"m:1\": check if merge keys are unique in right dataset:\n",
    "Name Date_Of_Birth Age\n",
    "0 Eesha Hinton 11/05/2002 22.0\n",
    "1 Syed Wharton 15/09/1997 23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41554b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "             Name Date_Of_Birth   Age\n",
      "0  Alberto Franco    17/05/2002  18.5\n",
      "1    Gino Mcneill    16/02/1999  21.2\n",
      "2     Ryan Parkes    25/09/1998  22.5\n",
      "3    Eesha Hinton    11/05/2002  22.0\n",
      "4    Syed Wharton    15/09/1997  23.0\n",
      "New DataFrames:\n",
      "           Name Date_Of_Birth   Age\n",
      "0   Ryan Parkes    25/09/1998  22.5\n",
      "1  Eesha Hinton    11/05/2002  22.0\n",
      "2  Syed Wharton    15/09/1997  23.0\n",
      "             Name Date_Of_Birth   Age\n",
      "0  Alberto Franco    17/05/2002  18.5\n",
      "1    Gino Mcneill    16/02/1999  21.2\n",
      "2    Eesha Hinton    11/05/2002  22.0\n",
      "3    Syed Wharton    15/09/1997  23.0\n",
      "\"one_to_one\": check if merge keys are unique in both left and right datasets:\n",
      "           Name Date_Of_Birth   Age\n",
      "0   Ryan Parkes    25/09/1998  22.5\n",
      "1  Eesha Hinton    11/05/2002  22.0\n",
      "2  Syed Wharton    15/09/1997  23.0\n",
      "\"one_to_many\" or \"1:m\": check if merge keys are unique in left dataset:\n",
      "             Name Date_Of_Birth_x  Age_x Date_Of_Birth_y  Age_y\n",
      "0  Alberto Franco      17/05/2002   18.5      17/05/2002   18.5\n",
      "1    Gino Mcneill      16/02/1999   21.2      16/02/1999   21.2\n",
      "2    Eesha Hinton      11/05/2002   22.0      11/05/2002   22.0\n",
      "3    Syed Wharton      15/09/1997   23.0      15/09/1997   23.0\n",
      "\"any_to_one\" or \"m:1\": check if merge keys are unique in right dataset:\n",
      "             Name Date_Of_Birth_x  Age_x Date_Of_Birth_y  Age_y\n",
      "0  Alberto Franco      17/05/2002   18.5      17/05/2002   18.5\n",
      "1    Gino Mcneill      16/02/1999   21.2      16/02/1999   21.2\n",
      "2    Eesha Hinton      11/05/2002   22.0      11/05/2002   22.0\n",
      "3    Syed Wharton      15/09/1997   23.0      15/09/1997   23.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "df = pd.DataFrame({'Name': ['Alberto Franco', 'Gino Mcneill', 'Ryan Parkes', 'Eesha Hinton', 'Syed Wharton'],\n",
    "                   'Date_Of_Birth': ['17/05/2002', '16/02/1999', '25/09/1998', '11/05/2002', '15/09/1997'],\n",
    "                   'Age': [18.5, 21.2, 22.5, 22.0, 23.0]})\n",
    "\n",
    "# Create the new DataFrames to merge\n",
    "new_df1 = pd.DataFrame({'Name': ['Ryan Parkes', 'Eesha Hinton', 'Syed Wharton'],\n",
    "                        'Date_Of_Birth': ['25/09/1998', '11/05/2002', '15/09/1997'],\n",
    "                        'Age': [22.5, 22.0, 23.0]})\n",
    "\n",
    "new_df2 = pd.DataFrame({'Name': ['Alberto Franco', 'Gino Mcneill', 'Eesha Hinton', 'Syed Wharton'],\n",
    "                        'Date_Of_Birth': ['17/05/2002', '16/02/1999', '11/05/2002', '15/09/1997'],\n",
    "                        'Age': [18.5, 21.2, 22.0, 23.0]})\n",
    "\n",
    "# Print the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Print the new DataFrames\n",
    "print(\"New DataFrames:\")\n",
    "print(new_df1)\n",
    "print(new_df2)\n",
    "\n",
    "# Perform the merge and check uniqueness\n",
    "one_to_one_merge = pd.merge(df, new_df1, on=['Name', 'Date_Of_Birth', 'Age'], how='inner')\n",
    "one_to_many_merge = pd.merge(df, new_df2, on=['Name'], how='inner')\n",
    "any_to_one_merge = pd.merge(df, new_df2, on=['Name'], how='right')\n",
    "\n",
    "# Print the merge results\n",
    "print('\"one_to_one\": check if merge keys are unique in both left and right datasets:')\n",
    "print(one_to_one_merge)\n",
    "print('\"one_to_many\" or \"1:m\": check if merge keys are unique in left dataset:')\n",
    "print(one_to_many_merge)\n",
    "print('\"any_to_one\" or \"m:1\": check if merge keys are unique in right dataset:')\n",
    "print(any_to_one_merge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452d26f8",
   "metadata": {},
   "source": [
    "# 70. Write a Pandas program to convert continuous values of a column in a given DataFrame to categorical.\n",
    "Input:\n",
    "{ 'Name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Syed Wharton'],\n",
    "'Age': [18, 22, 40, 50, 80, 5] }\n",
    "Output:\n",
    "Age group:\n",
    "0 kids\n",
    "1 adult\n",
    "2 elderly\n",
    "3 adult\n",
    "4 elderly\n",
    "5 kids\n",
    "Name: age_groups, dtype: category\n",
    "Categories (3, object): [kids < adult < elderly]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cf881f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Create the input DataFrame\u001b[39;00m\n\u001b[0;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlberto Franco\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGino Mcneill\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRyan Parkes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEesha Hinton\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSyed Wharton\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m22\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m80\u001b[39m, \u001b[38;5;241m5\u001b[39m]}\n\u001b[1;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Define the age group boundaries and labels\u001b[39;00m\n\u001b[0;32m      9\u001b[0m age_bins \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m60\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the input DataFrame\n",
    "data = {'Name': ['Alberto Franco', 'Gino Mcneill', 'Ryan Parkes', 'Eesha Hinton', 'Syed Wharton'],\n",
    "        'Age': [18, 22, 40, 50, 80, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define the age group boundaries and labels\n",
    "age_bins = [0, 18, 60, float('inf')]\n",
    "age_labels = ['kids', 'adult', 'elderly']\n",
    "\n",
    "# Convert the 'Age' column to categorical\n",
    "df['age_groups'] = pd.cut(df['Age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "# Print the output\n",
    "print(\"Age group:\")\n",
    "print(df['age_groups'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5286c3b0",
   "metadata": {},
   "source": [
    "# 71. Write a Pandas program to display memory usage of a given DataFrame and every column of the DataFrame.\n",
    "Sample Output:\n",
    "Original DataFrame:\n",
    "Name Date_Of_Birth Age\n",
    "0 Alberto Franco 17/05/2002 18.5\n",
    "1 Gino Mcneill 16/02/1999 21.2\n",
    "2 Ryan Parkes 25/09/1998 22.5\n",
    "3 Eesha Hinton 11/05/2002 22.0\n",
    "4 Syed Wharton 15/09/1997 23.0\n",
    "Global usage of memory of the DataFrame:\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 5 entries, 0 to 4\n",
    "Data columns (total 3 columns):\n",
    "Name 5 non-null object\n",
    "Date_Of_Birth 5 non-null object\n",
    "Age 5 non-null float64\n",
    "dtypes: float64(1), object(2)\n",
    "memory usage: 801.0 bytes\n",
    "None\n",
    "The usage of memory of every column of the said DataFrame:\n",
    "Index 80\n",
    "Name 346\n",
    "Date_Of_Birth 335\n",
    "Age 40\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506b8ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "data = {'Name': ['Alberto Franco', 'Gino Mcneill', 'Ryan Parkes', 'Eesha Hinton', 'Syed Wharton'],\n",
    "        'Date_Of_Birth': ['17/05/2002', '16/02/1999', '25/09/1998', '11/05/2002', '15/09/1997'],\n",
    "        'Age': [18.5, 21.2, 22.5, 22.0, 23.0]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Display memory usage of the DataFrame\n",
    "print(\"Global usage of memory of the DataFrame:\")\n",
    "print(df.info())\n",
    "\n",
    "# Display memory usage of every column of the DataFrame\n",
    "print(\"The usage of memory of every column of the DataFrame:\")\n",
    "print(df.memory_usage())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7338ad06",
   "metadata": {},
   "source": [
    "# 72. Write a Pandas program to combine many given series to create a DataFrame.\n",
    "Sample Output:\n",
    "Original Series:\n",
    "0 php\n",
    "1 python\n",
    "2 java\n",
    "3 c#\n",
    "4 c++\n",
    "dtype: object\n",
    "0 1\n",
    "1 2\n",
    "2 3\n",
    "3 4\n",
    "4 5\n",
    "dtype: int64\n",
    "Combine above series to a dataframe:\n",
    "index 0\n",
    "0 1 python\n",
    "1 2 java\n",
    "2 3 c#\n",
    "3 4 c++\n",
    "4 5 NaN\n",
    "Using pandas concat:\n",
    "0 1\n",
    "0 php 1\n",
    "1 python 2\n",
    "2 java 3\n",
    "3 c# 4\n",
    "4 c++ 5\n",
    "Using pandas DataFrame with a dictionary, gives a specific name to the columns:\n",
    "col1 col2\n",
    "0 php 1\n",
    "1 python 2\n",
    "2 java 3\n",
    "3 c# 4\n",
    "4 c++ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a403ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original series\n",
    "series1 = pd.Series(['php', 'python', 'java', 'c#', 'c++'])\n",
    "series2 = pd.Series([1, 2, 3, 4, 5])\n",
    "\n",
    "# Print the original series\n",
    "print(\"Original Series:\")\n",
    "print(series1)\n",
    "print(series2)\n",
    "\n",
    "# Combine the series using pd.concat()\n",
    "concatenated_df = pd.concat([series1, series2], axis=1)\n",
    "print(\"Combine above series to a DataFrame using pd.concat():\")\n",
    "print(concatenated_df)\n",
    "\n",
    "# Combine the series using DataFrame with a dictionary\n",
    "dict_df = pd.DataFrame({'col1': series1, 'col2': series2})\n",
    "print(\"Combine above series to a DataFrame using DataFrame with a dictionary:\")\n",
    "print(dict_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e457f4a",
   "metadata": {},
   "source": [
    "# 73. Write a Pandas program to create DataFrames that contains random values, contains missing values, contains datetime values and contains mixed values.\n",
    "Sample Output:\n",
    "DataFrame: Contains random values:\n",
    "A B C D\n",
    "Dog2w4Dv4l 0.591058 1.883454 -1.608613 -0.502516\n",
    "kV7mfdFcF9 0.629642 -0.474377 0.567357 1.658445\n",
    ".......\n",
    "DataFrame: Contains missing values:\n",
    "A B C D\n",
    "i6i6Xn9l9c -0.299335 0.410871 -0.431840 -0.302177\n",
    "OGo5KNNYNJ -0.174594 -1.366146 0.435063 -2.779446\n",
    "u0mG9q1L7C 1.019094 -0.061077 -1.138138 -0.218460\n",
    "RNJGqpci4o -0.380815 0.189970 -2.148521 -1.163589\n",
    "vXIcxItZ1D NaN -0.079448 0.604777 0.065290\n",
    "........\n",
    "DataFrame: Contains datetime values:\n",
    "A B C D\n",
    "2000-01-03 0.665402 0.860808 -0.180986 -0.970889\n",
    "2000-01-04 -1.511533 0.487539 -0.710355 -0.807816\n",
    "2000-01-05 -0.773294 0.197918 -1.214035 1.049529\n",
    "2000-01-06 -1.074894 1.774147 -0.620025 0.740779\n",
    ".......\n",
    "DataFrame: Contains mixed values:\n",
    "A B C D\n",
    "0 0.0 0.0 foo1 2009-01-01\n",
    "1 1.0 1.0 foo2 2009-01-02\n",
    "2 2.0 0.0 foo3 2009-01-05\n",
    "3 3.0 1.0 foo4 2009-01-06\n",
    "4 4.0 0.0 foo5 2009-01-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df1eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create DataFrame with random values\n",
    "df_random = pd.DataFrame(np.random.randn(5, 4), columns=['A', 'B', 'C', 'D'])\n",
    "print(\"DataFrame: Contains random values:\")\n",
    "print(df_random)\n",
    "\n",
    "# Create DataFrame with missing values\n",
    "df_missing = pd.DataFrame({'A': [-0.299335, -0.174594, 1.019094, -0.380815, np.nan],\n",
    "                           'B': [0.410871, -1.366146, -0.061077, 0.189970, -0.079448],\n",
    "                           'C': [-0.431840, 0.435063, -1.138138, -2.148521, 0.604777],\n",
    "                           'D': [-0.302177, -2.779446, -0.218460, -1.163589, 0.065290]})\n",
    "print(\"DataFrame: Contains missing values:\")\n",
    "print(df_missing)\n",
    "\n",
    "# Create DataFrame with datetime values\n",
    "df_datetime = pd.DataFrame({'A': pd.to_datetime(['2000-01-03', '2000-01-04', '2000-01-05', '2000-01-06']),\n",
    "                            'B': [0.665402, -1.511533, -0.773294, -1.074894],\n",
    "                            'C': [0.860808, 0.487539, 0.197918, 1.774147],\n",
    "                            'D': [-0.180986, -0.710355, -1.214035, -0.620025]})\n",
    "print(\"DataFrame: Contains datetime values:\")\n",
    "print(df_datetime)\n",
    "\n",
    "# Create DataFrame with mixed values\n",
    "df_mixed = pd.DataFrame({'A': [0.0, 1.0, 2.0, 3.0, 4.0],\n",
    "                         'B': [0.0, 1.0, 0.0, 1.0, 0.0],\n",
    "                         'C': ['foo1', 'foo2', 'foo3', 'foo4', 'foo5'],\n",
    "                         'D': pd.to_datetime(['2009-01-01', '2009-01-02', '2009-01-05', '2009-01-06', '2009-01-07'])})\n",
    "print(\"DataFrame: Contains mixed values:\")\n",
    "print(df_mixed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44783edd",
   "metadata": {},
   "source": [
    "# 74. Write a Pandas program to fill missing values in time series data.\n",
    "From Wikipedia , in the mathematical field of numerical analysis, interpolation is a type of estimation, a method of constructing new data points within the range of a discrete set of known data points.\n",
    "Sample Output:\n",
    "Original DataFrame:\n",
    "c1 c2\n",
    "2000-01-03 120.0 7.0\n",
    "2000-01-04 130.0 NaN\n",
    "2000-01-05 140.0 10.0\n",
    "2000-01-06 150.0 NaN\n",
    "2000-01-07 NaN 5.5\n",
    "2000-01-10 170.0 16.5\n",
    "DataFrame after interpolate:\n",
    "c1 c2\n",
    "2000-01-03 120.0 7.00\n",
    "2000-01-04 130.0 8.50\n",
    "2000-01-05 140.0 10.00\n",
    "2000-01-06 150.0 7.75\n",
    "2000-01-07 160.0 5.50\n",
    "2000-01-10 170.0 16.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e37a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "df = pd.DataFrame({'c1': [120.0, 130.0, 140.0, 150.0, None, 170.0],\n",
    "                   'c2': [7.0, None, 10.0, None, 5.5, 16.5]},\n",
    "                  index=pd.to_datetime(['2000-01-03', '2000-01-04', '2000-01-05',\n",
    "                                       '2000-01-06', '2000-01-07', '2000-01-10']))\n",
    "\n",
    "# Fill missing values using interpolation\n",
    "df_interpolated = df.interpolate()\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(\"DataFrame after interpolate:\")\n",
    "print(df_interpolated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cc7e88",
   "metadata": {},
   "source": [
    "# 75. Write a Pandas program to use a local variable within a query.\n",
    "Sample Output:\n",
    "Original DataFrame\n",
    "W X Y Z\n",
    "0 68 78 84 86\n",
    "1 75 85 94 97\n",
    "2 86 96 89 96\n",
    "3 80 80 83 72\n",
    "4 66 86 86 83\n",
    "Values which are less than maximum value of 'W' column\n",
    "W X Y Z\n",
    "0 68 78 84 86\n",
    "1 75 85 94 97\n",
    "3 80 80 83 72\n",
    "4 66 86 86 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a09543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "df = pd.DataFrame({'W': [68, 75, 86, 80, 66],\n",
    "                   'X': [78, 85, 96, 80, 86],\n",
    "                   'Y': [84, 94, 89, 83, 86],\n",
    "                   'Z': [86, 97, 96, 72, 83]})\n",
    "\n",
    "# Define the local variable\n",
    "max_value_W = df['W'].max()\n",
    "\n",
    "# Use the local variable within the query\n",
    "result = df.query(\"W < @max_value_W\")\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(\"Values which are less than maximum value of 'W' column:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6814837",
   "metadata": {},
   "source": [
    "# 76. Write a Pandas program to clean object column with mixed data of a given DataFrame using regular expression.\n",
    "Sample Output:\n",
    "Original dataframe:\n",
    "agent purchase\n",
    "0 a001 4500\n",
    "1 a002 7500\n",
    "2 a003 $3000.25\n",
    "3 a003 $1250.35\n",
    "4 a004 9000.00\n",
    "Data Types:\n",
    "0 <class 'float'>\n",
    "1 <class 'float'>\n",
    "2 <class 'str'>\n",
    "3 <class 'str'>\n",
    "4 <class 'str'>\n",
    "Name: purchase, dtype: object\n",
    "New Data Types:\n",
    "0 <class 'float'>\n",
    "1 <class 'float'>\n",
    "2 <class 'float'>\n",
    "3 <class 'float'>\n",
    "4 <class 'float'>\n",
    "Name: purchase, dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3757f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "data = {'agent': ['a001', 'a002', 'a003', 'a003', 'a004'],\n",
    "        'purchase': ['4500', '7500', '$3000.25', '$1250.35', '9000.00']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the original DataFrame\n",
    "print(\"Original dataframe:\")\n",
    "print(df)\n",
    "\n",
    "# Clean the 'purchase' column using regular expressions\n",
    "df['purchase'] = df['purchase'].str.replace(r'[^\\d.]', '', regex=True).astype(float)\n",
    "\n",
    "# Print the data types of the 'purchase' column\n",
    "print(\"Data Types:\")\n",
    "print(df['purchase'].apply(type))\n",
    "\n",
    "# Print the new data types of the 'purchase' column\n",
    "print(\"New Data Types:\")\n",
    "print(df['purchase'].apply(type).astype(str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73307e1c",
   "metadata": {},
   "source": [
    "# 77. Write a Pandas program to get the numeric representation of an array by identifying distinct values of a given column of a dataframe.\n",
    "Sample Output:\n",
    "Original DataFrame:\n",
    "Name Date_Of_Birth Age\n",
    "0 Alberto Franco 17/05/2002 18.5\n",
    "1 Gino Mcneill 16/02/1999 21.2\n",
    "2 Ryan Parkes 25/09/1998 22.5\n",
    "3 Eesha Hinton 11/05/2002 22.0\n",
    "4 Gino Mcneill 15/09/1997 23.0\n",
    "Numeric representation of an array by identifying distinct values:\n",
    "[0 1 2 3 1]\n",
    "Index(['Alberto Franco', 'Gino Mcneill', 'Ryan Parkes', 'Eesha Hinton'], dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddfddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create the original DataFrame\n",
    "data = {'Name': ['Alberto Franco', 'Gino Mcneill', 'Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill'],\n",
    "        'Date_Of_Birth': ['17/05/2002', '16/02/1999', '25/09/1998', '11/05/2002', '15/09/1997'],\n",
    "        'Age': [18.5, 21.2, 22.5, 22.0, 23.0]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Get the numeric representation of the column\n",
    "numeric_representation = pd.factorize(df['Name'])[0]\n",
    "\n",
    "# Print the numeric representation\n",
    "print(\"Numeric representation of an array by identifying distinct values:\")\n",
    "print(numeric_representation)\n",
    "print(\"Index:\")\n",
    "print(pd.factorize(df['Name'])[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d248fd30",
   "metadata": {},
   "source": [
    "# 78. Write a Pandas program to replace the current value in a dataframe column based on last largest value. If the current value is less than last largest value replaces the value with 0.\n",
    "Test data:\n",
    "rnum\n",
    "0 23\n",
    "1 21\n",
    "2 27\n",
    "3 22\n",
    "...\n",
    "10 34\n",
    "11 19\n",
    "12 31\n",
    "13 32\n",
    "14 19\n",
    "Sample Output:\n",
    "Original DataFrame:\n",
    "rnum\n",
    "0 23\n",
    "1 21\n",
    "2 27\n",
    "3 22\n",
    "...\n",
    "10 34\n",
    "11 19\n",
    "12 31\n",
    "13 32\n",
    "14 19\n",
    "Replace current value in a dataframe column based on last largest value:\n",
    "rnum\n",
    "0 23\n",
    "1 0\n",
    "2 27\n",
    "3 0\n",
    "...\n",
    "10 34\n",
    "11 0\n",
    "12 0\n",
    "13 0\n",
    "14 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe12c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the original DataFrame\n",
    "data = {'rnum': [23, 21, 27, 22, 34, 19, 31, 32, 19]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Replace current values based on last largest value\n",
    "last_largest = 0\n",
    "for i, value in enumerate(df['rnum']):\n",
    "    if value < last_largest:\n",
    "        df.at[i, 'rnum'] = 0\n",
    "    else:\n",
    "        last_largest = value\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(\"Replace current value in a DataFrame column based on last largest value:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711bbdc6",
   "metadata": {},
   "source": [
    "# 79. Write a Pandas program to create a DataFrame from the clipboard (data from an Excel spreadsheet or a Google Sheet).\n",
    "Sample Excel Data:\n",
    "Python Exercises: Sample Excel data.\n",
    "Sample Output:\n",
    "Data from clipboard to DataFrame:\n",
    "1 2 3 4\n",
    "0 2 3 4 5\n",
    "1 4 5 1 0\n",
    "2 2 3 7 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64ddad95",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Expected 4 fields in line 6, saw 5. Error could possibly be due to quotes being ignored when a multi-char delimiter is used.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Read data from clipboard to DataFrame\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_clipboard\u001b[49m\u001b[43m(\u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43ms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Print the DataFrame\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData from clipboard to DataFrame:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\clipboards.py:88\u001b[0m, in \u001b[0;36mread_clipboard\u001b[1;34m(sep, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sep) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     83\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread_clipboard with regex separator does not work properly with c engine.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     85\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m     86\u001b[0m     )\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m read_csv(StringIO(text), sep\u001b[38;5;241m=\u001b[39msep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m     (\n\u001b[0;32m   1775\u001b[0m         index,\n\u001b[0;32m   1776\u001b[0m         columns,\n\u001b[0;32m   1777\u001b[0m         col_dict,\n\u001b[1;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:282\u001b[0m, in \u001b[0;36mPythonParser.read\u001b[1;34m(self, rows)\u001b[0m\n\u001b[0;32m    279\u001b[0m     indexnamerow \u001b[38;5;241m=\u001b[39m content[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    280\u001b[0m     content \u001b[38;5;241m=\u001b[39m content[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 282\u001b[0m alldata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rows_to_cols\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m data, columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exclude_implicit_index(alldata)\n\u001b[0;32m    285\u001b[0m conv_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_data(data)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:1045\u001b[0m, in \u001b[0;36mPythonParser._rows_to_cols\u001b[1;34m(self, content)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             reason \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1040\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError could possibly be due to quotes being \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1041\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignored when a multi-char delimiter is used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1042\u001b[0m             )\n\u001b[0;32m   1043\u001b[0m             msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m reason\n\u001b[1;32m-> 1045\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_alert_malformed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_num\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;66;03m# see gh-13320\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m zipped_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(lib\u001b[38;5;241m.\u001b[39mto_object_array(content, min_width\u001b[38;5;241m=\u001b[39mcol_len)\u001b[38;5;241m.\u001b[39mT)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:765\u001b[0m, in \u001b[0;36mPythonParser._alert_malformed\u001b[1;34m(self, msg, row_num)\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;124;03mAlert a user about a malformed row, depending on value of\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;124;03m`self.on_bad_lines` enum.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;124;03m    even though we 0-index internally.\u001b[39;00m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_bad_lines \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBadLineHandleMethod\u001b[38;5;241m.\u001b[39mERROR:\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ParserError(msg)\n\u001b[0;32m    766\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_bad_lines \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mBadLineHandleMethod\u001b[38;5;241m.\u001b[39mWARN:\n\u001b[0;32m    767\u001b[0m     base \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mParserError\u001b[0m: Expected 4 fields in line 6, saw 5. Error could possibly be due to quotes being ignored when a multi-char delimiter is used."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data from clipboard to DataFrame\n",
    "df = pd.read_clipboard(sep='\\s')\n",
    "\n",
    "# Print the DataFrame\n",
    "print(\"Data from clipboard to DataFrame:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3878b597",
   "metadata": {},
   "source": [
    "# 80. Write a Pandas program to check for inequality of two given DataFrames.\n",
    "Sample Output:\n",
    "Original DataFrames:\n",
    "W X Y Z\n",
    "0 68.0 78.0 84 86\n",
    "1 75.0 85.0 94 97\n",
    "2 86.0 NaN 89 96\n",
    "3 80.0 80.0 83 72\n",
    "4 NaN 86.0 86 83\n",
    "W X Y Z\n",
    "0 78.0 78 84 86\n",
    "1 75.0 85 84 97\n",
    "2 86.0 96 89 96\n",
    "3 80.0 80 83 72\n",
    "4 NaN 76 86 83\n",
    "Check for inequality of the said dataframes:\n",
    "W X Y Z\n",
    "0 True False False False\n",
    "1 False False True False\n",
    "2 False True False False\n",
    "3 False False False False\n",
    "4 True True False False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b77b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Original DataFrames\n",
    "df1 = pd.DataFrame({'W': [68.0, 75.0, 86.0, 80.0, np.nan],\n",
    "                    'X': [78.0, 85.0, np.nan, 80.0, 86.0],\n",
    "                    'Y': [84, 94, 89, 83, 86],\n",
    "                    'Z': [86, 97, 96, 72, 83]})\n",
    "\n",
    "df2 = pd.DataFrame({'W': [78.0, 75.0, 86.0, 80.0, np.nan],\n",
    "                    'X': [78, 85, 96, 80, 76],\n",
    "                    'Y': [84, 84, 89, 83, 86],\n",
    "                    'Z': [86, 97, 96, 72, 83]})\n",
    "\n",
    "# Check for inequality of the two DataFrames\n",
    "inequality = df1 != df2\n",
    "\n",
    "# Print the inequality DataFrame\n",
    "print(\"Check for inequality of the two DataFrames:\")\n",
    "print(inequality)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d788f7b",
   "metadata": {},
   "source": [
    "# 81. Write a Pandas program to get lowest n records within each group of a given DataFrame.\n",
    "Sample Output:\n",
    "Original DataFrame\n",
    "col1 col2 col3\n",
    "0 1 4 7\n",
    "1 2 5 5\n",
    "2 3 6 8\n",
    "3 4 9 12\n",
    "4 7 5 1\n",
    "5 11 0 11\n",
    "Lowest n records within each group of a DataFrame:\n",
    "col1 col2 col3\n",
    "0 1 4 7\n",
    "1 2 5 5\n",
    "2 3 6 8\n",
    "col1 col2 col3\n",
    "5 11 0 11\n",
    "0 1 4 7\n",
    "1 2 5 5\n",
    "col1 col2 col3\n",
    "4 7 5 1\n",
    "1 2 5 5\n",
    "0 1 4 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c92b049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Original DataFrame\n",
    "df = pd.DataFrame({'col1': [1, 2, 3, 4, 7, 11],\n",
    "                   'col2': [4, 5, 6, 9, 5, 0],\n",
    "                   'col3': [7, 5, 8, 12, 1, 11]})\n",
    "\n",
    "# Function to get the lowest n records within each group\n",
    "def get_lowest_n_records(group, n):\n",
    "    return group.nsmallest(n, 'col1')\n",
    "\n",
    "# Group by 'col1' and get the lowest 2 records within each group\n",
    "lowest_n_records = df.groupby('col1').apply(get_lowest_n_records, n=2).reset_index(drop=True)\n",
    "\n",
    "# Print the lowest n records within each group\n",
    "print(\"Lowest 2 records within each group of the DataFrame:\")\n",
    "print(lowest_n_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d38de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c55cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
